\documentclass[]{article}   % list options between brackets
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[margin=0.75in]{geometry}            % list packages between braces

% type user-defined commands here

\begin{document}

\title{infer\_sde user manual}   % type title between braces
\author{Cyril Galitzine}         % type author(s) between braces
\date{\today}    % type date between braces
\maketitle


\section{Introduction}     % section 

infer\_sde is a Python code that allows the inference of the distribution of the rates of a stochastic differential equation (SDE) from a single or multiple noisy observation(s) of its trajectory. It is based on a Markov chain Monte Carlo (MCMC) method which samples from the posterior rate distribution. The likelihood of the data is estimated via a particle filter method. Further details about the inference method can be found in \cite{Galitzine}

 It was initially created to infer the rates governing peroxisome dynamics \cite{Galitzine}. In such situation, we are interested in inferring three rates $k_{d}, k_{f}, \gamma$ and the standard deviation of the measurement error $\sigma$. The peroxisome count $X_{t}$ at time $t$ is governed by the following SDE:
\begin{equation}
d X_{t} = \left[k_{d} + \left(k_{f} - \gamma\right) X_{t} \right] dt + \left[k_{d} + \left(k_{f} + \gamma\right) X_{t} \right]^{1/2} d W_{t}
\label{BDI} 
\end{equation}
which corresponds to a birth-death-immigration (BDI) stochastic process.
We simultaneously observe multiple \emph{realizations} of this SDE by measuring the $X_{t}$ time course in multiple cells. Each realization of the stochastic process is called a \emph{replicate} in the following the biology terminology.

The code can readily be extended to other types of SDEs because of its modular object oriented design.

\section{Running the code}     % section 2.1
\subsection{Input files}    
	\subsubsection{sim.dat}
	This file is used to simulate data which is then stored the data.csv file. A typical sim.dat file is reproduced below:
	\verbatiminput{sim.dat}
The different lines of the file are described below:	
\begin{itemize}
\item {\tt{Equation\_sim}}: Name of the SDE to simulate. Currently the following SDE are available:
\begin{description}
 \item {\tt BDI}: Eq.~(\ref{BDI}) with parameters $k_{d},k_{f} \textrm{ and } \gamma$ (in that order). In this case the equivalent master equation is simulated via the Gillespie algorithm. This potentially avoid any error in the simulation of the SDE.
\end{description}
\item {\tt{Error\_model\_sim}}: Error model to use to simulate data. Currently the following models are available:
\begin{description}
 \item {\tt Normal}: Measured values $x_{\textrm{measured}}$ are obtained from the true hidden values, $x_{\textrm{hidden}}$ following $x_{\textrm{measured}} \sim \textrm{Normal}\left(\mu =  x_{\textrm{hidden}}, \sigma = \mathtt{error\_sim} \right)$. The standard deviation is assumed to be constant with time and the same for all replicates.
\end{description}
\item {\tt{Nrep\_sim}}: Number of replicates to simulate
\item {\tt{param\_sim}}: Value of the parameters used to simulate data. The order of the parameters has to correspond to that required by the SDE type.
\item {\tt{Rate\_heterogeneity\_model\_sim}}:
Heterogeneity model for the rates between replicates
\begin{description}
\item{\tt{Homogeneous}}: The data of all replicates is generated with the exact same rates
\item{\tt{Heterogeneous}}: Rates vary between replicates following a gamma distribution for each rate. When this option is used {\tt param\_sim} does not specify directly the rates of the SDE but instead the mean and standard deviation of the gamma distribution of each rate. Assuming that the standard deviation is 10\% of the rate mean, {\tt param\_sim} would become instead {\tt [7.75e-4,7.75e-5,4.0e-5,4.0e-6,4.0e-5,4.0e-6]} of {\tt [7.75e-4,4.0e-5,4.0e-5} for {\tt Homogeneous} rate model.
\end{description}
\item {\tt{Error\_heterogeneity\_model\_sim}}:
\begin{description}
\item{\tt{Homogeneous}}: The data of all replicates is generated with the same error standard deviation.
\end{description}
\item {\tt{X0\_sim}}: Initial value at time $t=0$. This value should be specified for each {\tt N\_rep\_sim} replicate. If it is not the initial value is determined via Poisson distribution with $\lambda=$ {\tt X0\_sim}.
\item {\tt{Ntime\_sim}}: Number of time points (A constant $\Delta t$ is used)
\item {\tt{T\_sim}}: Overall simulation time (has to be in the same time unit as the rate specified with {\tt{param\_sim}}).
 \end{itemize}
		
	
      \subsubsection{data.csv}
      data.csv contains the time course data that is used for the inference. It can be either generated by simulation or obtained through experimental measurement. The first few lines of typical data.csv file are reproduced below:
	\verbatiminput{data.csv}
      The first column corresponds to the index of the DataFrame is not important. It does not need to be specified. The following comma separated columns: {\tt replicate, t, x} should always be present. The number of replicate starts at 0 and should always be specified even if there is only a single replicate.
\newpage      
  \subsubsection{inference.dat}
  
  The inference.dat file controls the inference procedure. A typical inference.dat file (the one used in example BDI\_4rep\_homogeneous\_rates\_parallel) is detailed below:
        \verbatiminput{inference.dat}

\begin{itemize}
\item {\tt{Simulate\_data}}: 0: Read existing data.csv file (if it exists), 1: Simulate new data 
\item {\tt{Equation}}: Name of the SDE to simulate. Currently the following SDE(s) are available:
\begin{description}
 \item {\tt BDI}: Eq.~(\ref{BDI}) with parameters $k_{d},k_{f} \textrm{ and } \gamma$ (in that order).
\end{description}
\item {\tt{Error\_model}}: Error model for the data. Currently the following models are available:
\begin{description}
 \item {\tt Normal}: Measured values $x_{\textrm{measured}}$ are obtained from the true hidden values, $x_{\textrm{hidden}}$ following $x_{\textrm{measured}} \sim \textrm{Normal}\left(\mu =  x_{\textrm{hidden}}, \sigma = \mathtt{error\_sim} \right)$. The standard deviation is assumed to be constant with time for each replicate.
\end{description}
\item {\tt{Nsamp}}: Number of accepted MCMC samples to calculate. MCMC sample proposals that are not accepted are not counted.
\item {\tt{Npart}}: Number of particles to use for the particle filter
\item {\tt{param}}: Initial starting value for the parameters at step 0. The parameters have to be in the correct order dictated by {\tt Equation}.
\item {\tt{param\_infer}}: Infer parameter of {\tt param} 0/1 = Yes/No. In case param\_infer=0 for a particular parameter, its value is assumed constant and equal to that specified in {\tt param}.
\item {\tt{param\_error}}: Initial starting value for the error parameter at step 0. The names specified for the error parameters do not matter. Typically one error parameter is inferred for each replicate such as here.
\item {\tt{param\_error\_infer}}: Infer parameter of {\tt param\_error} 0/1 = Yes/No. In case param\_error\_infer=0 for a particular parameter, its value is assumed constant and equal to that specified in {\tt param\_error}.
\item {\tt{Rate\_heterogeneity\_model}}:
Heterogeneity model for the rates between replicates
\begin{description}
\item{\tt{Homogeneous}}: Assume that all replicates are governed by the exact same rates.
\item{\tt{Heterogeneous}}: Assume that rates vary between replicates following a gamma distribution for each rate. When this option is used {\tt param} does not specify directly the initial rate values of the SDE but instead the initial mean and standard deviation of the gamma distribution of each rate. Assuming that initially the standard deviation is 10\% of the rate mean, {\tt param\_sim} would become instead

 {\tt [7.75e-4,7.75e-5,4.0e-5,4.0e-6,4.0e-5,4.0e-6]} of {\tt [7.75e-4,4.0e-5,4.0e-5} for {\tt Homogeneous} rate model.
\end{description}
 \item {\tt{Error\_heterogeneity\_model}}:
 Heterogeneity model for the measurement error between replicates
 \begin{description}
\item{\tt{Homogeneous}}: Assumes that each replicate has a different error standard deviation. This terminology might be misleading but it used for consistency with the rate heterogeneity model. When this model is used, {\tt param\_error} needs to contain one error standard deviation for each replicate.
\end{description}
 \item {\tt{sd\_MH}}:
Parameter controlling the step size of the Metropolis Hastings algorithm. It should be adjusted so that the average acceptance rate is around 0.3.
 \item {\tt{MH\_step\_scaling}}: Metropolis Hasting stepping method. The following methods are available:
\begin{description}
\item{\tt{exponential}}: New samples are generated following a log-normal distribution centered on the current value, i.e.~$x^{n+1} = x^{n}\exp\left(Z\right)$ with $Z \sim \mathcal{N}\left(0,\sigma_{\textrm{MH\_step\_scaling}}\right)$. This stepping method ensures that each rate step is always properly scaled that the rates remains positive (rates are always defined to be positive).
\end{description}
 \end{itemize}


\subsection{Output files}

\subsubsection{out.dat}

This file contains the accepted MCMC samples (rejected samples are not recorded) for each of the parameter listed in the inference.dat file. It also contains the overall likelihood of the data. The out.dat file obtained with the inference.dat file shown above looks like this: (in small fonts to show everything...)
{\tiny \verbatiminput{out.dat}}
The columns correspond to the samples for rates specified in {\tt parama} and {\tt param\_error} (in the same order). The last column is the log likelihood calculated for that particular set of parameters.

\section{Running the code}

\subsection{Overall workflow} 

\subsection{Simulating data with infer\_sde\_serial.py}

To simulate data, remove any existing data.csv file and run the serial inference code: {\tt python infer\_sde\_serial.py} . You should have all the *.py files in the directory where you execute this command as well as the following required input files: {\tt sim.dat}, {\tt inference.dat}. 
 If you do not wish to perform inference simply stop the executing of the code after a few steps once you are sure that data.csv has been generated. 

You can plot the trajectories that you just generated in the {\tt data.csv} file by running {\tt python plot\_traj.py} which will produce a plot: {\tt data.png}

It is also likely that you will have to modify the code in time\_series.py to generate simulated data that conforms to your desired specifications This is because simulating data according to sim.dat can only produce a very narrow set of data types. For instance, it cannot generate replicates with different numbers of time points or overall times.

\subsection{Running the serial inference code with infer\_sde\_serial.py}

The inference code is executed by typing {\tt python infer\_sde\_serial.py}
You should have all the *.py files in the directory where you execute this command as well as the following required input files: {\tt sim.dat}, {\tt inference.dat} of course the data file {\tt data.csv}. When the code runs, it will output for each accepted sample the value of the parameters and measurement errors, the log likelihood (L), the max log likelihood (called Lmin) and the average acceptance ratio AR. The value of {\tt sd\_MH} in {\tt inference.dat} should be adjusted so that the acceptance ratio is around 0.3 (i.e.~the optimum acceptance ratio for the Metropolis Hastings algorithm).

\subsection{Running the parallel inference code with infer\_sde\_parallel.py}

The inference code was parallelized across replicates using a python version of the MPI library mpi4py. This allows us to split the calculation of the overall log likelihood across multiple CPUs to speed up the sampling procedure (but only when multiple replicates are considered). The $N_{\textrm{rep}}$ replicates are distributed as uniformly as possible across CPUs. Each CPU then calculates the sum of the log likelihoods of all the replicates that are assigned to it. The log likelihoods sums are then summed again across cpus to calculate the overall log likelihood. When using $N_{\textrm{CPU}}$ to run the inference, one CPU (the master CPU) will not be performing calculations. As such the calculation will be distributed among the remaining $N_{\textrm{CPU}} -1$ CPUs. For instance, if want to infer the rates for $N_{\textrm{rep}} = 4$ replicates and use  $N_{\textrm{CPU}}=5$, each CPU will calculate the likelihood of one replicate which leads to the optimal speedup. If $N_{\textrm{CPU}}=4$ are used for the same 4 replicates, the replicates will be split as follows across CPUs: $\overbrace{\textrm{Rep1}}^{\textrm{CPU 2}} \vert \overbrace{\textrm{Rep2}}^{\textrm{CPU 3}} \vert \overbrace{\textrm{Rep3},\textrm{Rep4}}^{\textrm{CPU 4}}$ The fourth CPU will calculate the likelihood of two replicates) while CPU 1, the master CPU, is not involved in the calculation of likelihoods. If $N_{\textrm{CPU}}=3$, we would obtain the following: $\overbrace{\textrm{Rep1},\textrm{Rep2}}^{\textrm{CPU 2}} \vert \overbrace{\textrm{Rep3},\textrm{Rep4}}^{\textrm{CPU 3}}$. $N_{\textrm{CPU}}=2$ should not be employed since the it will less efficient than the serial code the due to the master CPU.\\


To run the inference with, e.g. NCPUS = 4 the following should be executed:\\
{\tt mpirun -np 4 python3 infer\_sde\_parallel.py}


The inputs and outputs of the parallel code are identical to those of the serial code.

\subsection{Analyzing results with analyze\_mcmc.py}

The inference code (serial or parallel) produces an {\tt out.dat} file with the posterior rate samples. Plots of the distribution of the rates can be obtained by running {\tt python analyze\_mcmc.py}. This produces density (*\_density.pdf) and correlation (*\_corr.pdf) plots for the inferred parameters. The sampling frequency of the parameters ({\tt frequency} variable) in {analyze\_mcmc.py} should be adjusted so that the consecutive samples are not too correlated which otherwise results in an inaccurate estimation of the densities.

\newpage
\section{Test cases}
\subsection{BDI {(\small birth death immigration)} SDE: $dX_{t} =  \left[k_{d} + \left(k_{f} - \gamma\right) X_{t} \right] dt + \left[k_{d} + \left(k_{f} + \gamma\right) X_{t} \right]^{1/2} d W_{t}$}

\subsubsection{1 replicate, serial (EXAMPLES/BDI\_1rep)}

All the input, output files and results of the inference can be found in folder EXAMPLES/BDI\_1rep. Data was simulated according to the following sim.dat for a single replicate:
\verbatiminput{../EXAMPLES/BDI_1rep/sim.dat}
The serial inference code, {\tt infer\_sde\_serial.py}, was run for 24 hours and the results were analyzed with {\tt analyze\_mcmc.py}.


\subsubsection{4 replicates, Homogeneous rates, serial (EXAMPLES/BDI\_4rep\_homogeneous\_rates\_serial)}

All the input, output files and results of the inference can be found in folder EXAMPLES/BDI\_1rep. 
Data was simulated according to the following sim.dat for 4 replicates (homogeneous rates):
\verbatiminput{../EXAMPLES/BDI_4rep_homogeneous_rates_serial/sim.dat}
The serial inference code, {\tt infer\_sde\_serial.py}, was run for 24 hours and the results were analyzed with {\tt analyze\_mcmc.py}.


\subsubsection{4 replicates, Homogeneous rates, parallel (EXAMPLES/BDI\_4rep\_homogeneous\_rates\_parallel)}
The same data as for case BDI\_4rep\_homogeneous\_rates\_serial was used. The parallel inference code was run for 24 hours using 5 CPUs with {\tt mpirun -np 5 python infer\_sde\_parallel.py}. Results were then analyzed with {\tt analyze\_mcmc.py}.

\subsubsection{4 replicates, Heterogeneous rates, parallel (EXAMPLES/BDI\_4rep\_heterogeneous\_rates\_parallel)}
All the input, output files and results of the inference can be found in folder EXAMPLES/BDI\_4rep\_heterogeneous\_rates\_parallel. 
Data was simulated according to the following sim.dat for 4 replicates (heterogeneous rates between replicates):
\verbatiminput{../EXAMPLES/BDI_4rep_heterogeneous_rates_parallel/sim.dat}

\bibliography{bib.bib}

\bibliographystyle{plain}
\end{document}